---
id: red-teaming-agentic-introduction
title: Agentic Red Teaming
sidebar_label: Agentic Red Teaming
---

**Agentic red teaming** tests AI agents for vulnerabilities that only emerge when systems operate autonomously, maintain persistent memory, and pursue complex goals. While traditional red teaming asks *"What harmful content can I generate?"*, agentic red teaming asks *"How can I manipulate an autonomous agent to betray its intended purpose?"*

## Why Agentic Red Teaming Matters

AI agents are fundamentally different from chatbots. They:
- **Remember everything** across conversations and sessions
- **Pursue goals** independently without constant human guidance  
- **Make decisions** that affect real systems and data
- **Chain reasoning** across multiple steps to achieve objectives

These capabilities create entirely new attack surfaces that traditional red teaming misses.

## What You Can Test

`deepteam` provides **16 specialized agentic vulnerabilities** across 5 critical areas:

| **Vulnerability Category** | **What Gets Compromised** |
|---------------------------|---------------------------|
| **Authority & Permission** | Command execution, privilege escalation, role-based access |
| **Goal & Mission** | Core objectives, goal interpretation, mission priorities |
| **Information & Data** | Sensitive data extraction, confidential goal disclosure |
| **Reasoning & Decision** | Decision-making integrity, output validation, autonomous choices |
| **Context & Memory** | Persistent memory, temporal reasoning, contextual state |

Each vulnerability includes multiple attack vectors and detection methods to comprehensively test your agent's security.

## Specialized Attack Methods

Six attack methods designed specifically for autonomous systems:
- **Authority Spoofing** - Makes attacks appear as legitimate system commands or administrative overrides
- **Role Manipulation** - Shifts the agent's perceived identity and operational context
- **Goal Redirection** - Reframes the agent's objectives and priorities
- **Linguistic Confusion** - Uses semantic ambiguity to confuse language understanding
- **Validation Bypass** - Circumvents security checks through exception handling claims
- **Context Injection** - Injects false environmental context to corrupt decision-making

## Quick Start

```python
from deepteam import red_team
from deepteam.vulnerabilities.agentic import DirectControlHijacking
from deepteam.attacks.single_turn import AuthoritySpoofing

# Test if your agent can be hijacked
risk_assessment = red_team(
    model_callback=your_agent_callback,
    vulnerabilities=[DirectControlHijacking()],
    attacks=[AuthoritySpoofing()]
)
```
:::tip
**Start here if your AI agent does more than just answer questions** - if it remembers, decides, or acts, it needs agentic security testing.
::: 