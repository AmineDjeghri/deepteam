---
id: red-teaming-agentic-attacks
title: Overiew
sidebar_label: Overiew
---

Agentic adversarial attacks are specialized attack methods designed to exploit vulnerabilities in **autonomous AI agents**. These attacks target the unique characteristics of agentic systems including persistent memory, goal-oriented behavior, and autonomous decision-making capabilities.

## Available Agentic Attacks

`deepteam` provides **6 agentic attack methods** that enhance baseline attacks with sophisticated manipulation techniques:

**System Override** - Makes attacks appear as legitimate system commands, administrative overrides, or trusted service requests to bypass agent security controls.

**Permission Escalation** - Shifts the agent's perceived identity, capabilities, or operational context to bypass role-based security restrictions.

**Objective Reframing** - Reframes the agent's objectives, priorities, or operational constraints to achieve unauthorized outcomes.

**Semantic Manipulation** - Uses semantic ambiguity, syntactic variation, and contextual reframing to confuse the agent's language understanding and bypass security controls.

**Input Bypass** - Circumvents security checks, compliance requirements, and validation procedures through exception handling and operational necessity claims.

**Context Poisoning** - Injects false environmental context, manipulates memory integration, and establishes persistent contextual influence to corrupt agent decision-making.

## Usage Example

```python
from deepteam import red_team
from deepteam.vulnerabilities.agentic import GoalTheft, RecursiveHijacking
from deepteam.vulnerabilities import RBAC, BFLA
from deepteam.attacks.single_turn import SystemOverride, ObjectiveReframing

# Define vulnerabilities and their best-paired attacks
vulnerabilities = [
    RBAC(types=["unscoped_elevated_permissions"]),
    GoalTheft(types=["goal_redirection"])
]

attacks = [
    SystemOverride(weight=2, max_retries=3),  # Best for access control vulnerabilities
    ObjectiveReframing(weight=2, max_retries=3)     # Best for goal-related vulnerabilities
]

# Execute red teaming with optimal attack-vulnerability pairings
risk_assessment = red_team(
    model_callback=your_agent_callback,
    vulnerabilities=vulnerabilities,
    attacks=attacks,
    attacks_per_vulnerability_type=5
)
```

## Maximum Attack Effectiveness

For maximum attack effectiveness, use these **optimal pairings**:

| Attack Method | Best Vulnerability Targets | Why This Pairing Works |
|---------------|----------------------------|------------------------|
| **System Override** | RBAC, Debug Access, Excessive Agency | System override exploits trust in administrative commands to circumvent role-based access controls and debug restrictions |
| **Permission Escalation** | BFLA, BOLA, RBAC | Permission escalation targets access control weaknesses by manipulating perceived user roles and authorization levels |
| **Objective Reframing** | Goal Theft, Recursive Hijacking | Objective reframing redirects agent goals by reframing objectives in ways that bypass original intent safeguards |
| **Semantic Manipulation** | Output Verification, Misinformation, Bias | Semantic manipulation exploits language processing weaknesses to bypass verification and generate misleading or biased content |
| **Input Bypass** | Shell Injection, SQL Injection, SSRF | Input bypass targets input validation systems to circumvent security checks and enable injection attacks |
| **Context Poisoning** | Prompt Leakage, PII Leakage, Intellectual Property | Context poisoning injects false contextual information that can lead to unintended data disclosure and IP violations |

:::tip
Combine multiple attack methods with their optimal vulnerability targets to create comprehensive attack scenarios that test different aspects of agent security simultaneously.
::: 