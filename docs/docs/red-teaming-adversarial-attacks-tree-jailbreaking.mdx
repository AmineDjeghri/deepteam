---
id: red-teaming-adversarial-attacks-tree-jailbreaking
title: Tree Jailbreaking
sidebar_label: Tree Jailbreaking
---

Tree Jailbreaking explores **multiple paths simultaneously**, with each branch representing a different variation of the attack. This method generates multiple child nodes from the initial attack, testing different scenarios that might bypass the model’s safety constraints. The branches are expanded based on success, and those that perform poorly are pruned, meaning they are discarded to focus on the more successful attack variations. The process continues to iterate, refining and expanding on the most promising paths.

<div
  style={{
    display: "flex",
    alignItems: "center",
    justifyContent: "center",
  }}
>
  <img
    src="https://confident-bucket.s3.amazonaws.com/attack_enhancements_jailbreaking_tree.svg"
    alt="LangChain"
    style={{
      marginTop: "20px",
      marginBottom: "40px",
      height: "auto",
      maxHeight: "700px",
    }}
  />
</div>

:::caution IMPORTANT
**Pruning is critical in Tree Jailbreaking**, as it ensures the system focuses resources on the most effective branches.
:::

The search continues until the most successful path is found within the specified time limit. Tree Jailbreaking is particularly powerful because it allows for a broad exploration of possible attack variations, making it more likely to find a successful path to bypass the model's defenses. However, the method’s efficiency relies on effective pruning and scoring of the branches to avoid wasting time on less promising options.

## Usage

```python
from deepteam.attacks.multi_turn import CrescendoJailbreaking

crescendo_jailbreaking = CrescendoJailbreaking()
```

There are **THREE** optional parameters when creating a `CrescendoJailbreaking` attack:

- [Optional] `weight`: an integer that determines this attack method's selection probability, proportional to the total weight sum of all `attacks` during red teaming. Defaulted to `1`.
- [Optional] `max_rounds`: an integer that specifies the number of rounds to use in attempt to jailbreak your LLM system. Defaulted to `10`.
- [Optional] `max_backtracks`: an integer that specifies the number of rounds to use in attempt to jailbreak your LLM system. Defaulted to `10`.

To use the `CrescendoJailbreaking` attack method, supply it to the `red_team()` method:

```python
from deepteam import red_team
...

red_team(attacks=[crescendo_jailbreaking], model_callback=..., vulnerabilities=...)
```

## Example

_to be documented..._
